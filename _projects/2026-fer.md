---
title: "Face Emotion Recognition"
collection: projects
permalink: /projects/2026-fer/
---

<div style="text-align: justify;">
This academic work presents a series of experiments aimed at improving the performance of an artificial intelligence model dedicated to facial expression recognition. The primary objective is to optimize the detection of basic facial emotions from image data. The experiments are conducted using the Face Emotion Recognition (FER-2013) dataset.</div>

- [Github - Face emotion recognition](https://github.com/nd-serge/face-emotion-recognition)
- [Technical report - Face emotion recognition](https://drive.google.com/file/d/13kpGCybHdg9zN0HoxlmYmLg-kokP0LWq/view?usp=drive_link)

### Context 
---
<div style="text-align: justify;">

Facial emotion is an important modality used in affective analysis. The notebook explores several techniques to improve emotion detection from images using the Face Emotion Recognition (FER) dataset.

</div>

### Methodology
---
<div style="text-align: justify;">

First, we design a Convolutional Neural Network (CNN) and evaluate the impact of different optimizers, namely Adam, SGD, RMSProp, and Adagrad. To reduce overfitting and improve generalization, dropout layers are added to the network.

The second approach investigates transfer learning by leveraging pre-trained models such as VGG16 and VGG19.
</div>


### Result
--- 
<div style="text-align: justify;">

This study investigated methods to improve emotion detection using the FER-2013 dataset of 48 Ã— 48 grayscale images labeled with seven basic emotions. Experiments showed that for the developed CNN, RMSProp was the most effective optimizer, while fine-tuning a pre-trained VGG model achieved the highest overall accuracy of 0.53. The model still struggles to distinguish certain emotions, such as anger, fear, and sadness, which are often confused with neutral expressions. Further improvements could focus on enhanced data processing to better capture discriminative features and improve emotion separability.

</div>


